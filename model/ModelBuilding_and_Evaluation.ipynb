{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 926,
     "status": "ok",
     "timestamp": 1727947746365,
     "user": {
      "displayName": "biplov belbase",
      "userId": "02095037767289247533"
     },
     "user_tz": -345
    },
    "id": "TYrNx7EYtWGD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 497,
     "status": "ok",
     "timestamp": 1727951495073,
     "user": {
      "displayName": "biplov belbase",
      "userId": "02095037767289247533"
     },
     "user_tz": -345
    },
    "id": "9x0Tx92etiR-"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('CleanedData3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1727951536888,
     "user": {
      "displayName": "biplov belbase",
      "userId": "02095037767289247533"
     },
     "user_tz": -345
    },
    "id": "SKjqYLaD7-zk",
    "outputId": "c38adf9b-daf7-463d-c8e2-9f67b273ad8c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Floors</th>\n",
       "      <th>Area</th>\n",
       "      <th>Road_Width</th>\n",
       "      <th>City_Bhaktapur</th>\n",
       "      <th>City_Kathmandu</th>\n",
       "      <th>City_Lalitpur</th>\n",
       "      <th>Road_Type_Blacktopped</th>\n",
       "      <th>Road_Type_Gravelled</th>\n",
       "      <th>Road_Type_Soil Stabilized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.132908</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.576956</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.021003</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.688861</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.5000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.688861</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.8125</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Price  Floors     Area  Road_Width  City_Bhaktapur  City_Kathmandu  \\\n",
       "0  3.132908     2.0  16.0000        20.0               0               1   \n",
       "1  2.576956     2.0  21.0000        20.0               0               1   \n",
       "2  2.021003     2.0  17.0000        20.0               0               1   \n",
       "3  3.688861     2.0  19.5000        20.0               0               1   \n",
       "4  3.688861     3.0  12.8125        13.0               0               1   \n",
       "\n",
       "   City_Lalitpur  Road_Type_Blacktopped  Road_Type_Gravelled  \\\n",
       "0              0                      1                    0   \n",
       "1              0                      1                    0   \n",
       "2              0                      1                    0   \n",
       "3              0                      1                    0   \n",
       "4              0                      1                    0   \n",
       "\n",
       "   Road_Type_Soil Stabilized  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          0  \n",
       "3                          0  \n",
       "4                          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 432,
     "status": "ok",
     "timestamp": 1727951540626,
     "user": {
      "displayName": "biplov belbase",
      "userId": "02095037767289247533"
     },
     "user_tz": -345
    },
    "id": "T0u3gdew7vPT"
   },
   "outputs": [],
   "source": [
    "X = df.drop('Price', axis=1)\n",
    "y = df['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2466,
     "status": "ok",
     "timestamp": 1727951619558,
     "user": {
      "displayName": "biplov belbase",
      "userId": "02095037767289247533"
     },
     "user_tz": -345
    },
    "id": "8y65PeJJ8A1F"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.787106120878515\n",
      "R^2 Score: 0.21072428122034426\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize the MLPRegressor\n",
    "mlp_regressor = MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = mlp_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R^2 Score: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.74336967 0.11104259 0.73028506 0.63630999 0.61782073]\n",
      "Average cross-validation score: 0.57\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Initialize the MLPRegressor with desired parameters\n",
    "mlp = MLPRegressor(\n",
    "    hidden_layer_sizes=(50, 50),  # Two hidden layers with 50 neurons each\n",
    "    activation='relu',            # Activation function for hidden layers\n",
    "    solver='adam',                # Optimization algorithm\n",
    "    alpha=0.01,                  # L2 regularization strength\n",
    "    max_iter=1000,               # Maximum number of iterations\n",
    "    random_state=42              # For reproducibility\n",
    ")\n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "# Perform cross-validation and get the scores\n",
    "scores = cross_val_score(mlp, X, y, cv=cv, scoring='r2')\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation scores: %s\" % scores)\n",
    "print(\"Average cross-validation score: %.2f\" % scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8336183581874999"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr_clf = LinearRegression()\n",
    "lr_clf.fit(X_train,y_train)\n",
    "lr_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use K Fold cross validation to measure accuracy of our LinearRegression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.67290823, -1.05796964,  0.62014139,  0.54895838,  0.56768824])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "cross_val_score(LinearRegression(), X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in 5 iterations we get a score above 50 % all the time. This is not bad  but we want to test few other algorithms for regression to see if we can get even better score. We will use GridSearchCV or RandomizedSearchCV for this purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 3 is smaller than n_iter=10. Running 3 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "10 fits failed out of a total of 20.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'absolute_error', 'friedman_mse', 'squared_error', 'poisson'}. Got 'mse' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'friedman_mse', 'absolute_error', 'poisson', 'squared_error'}. Got 'mse' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'absolute_error', 'squared_error', 'poisson', 'friedman_mse'}. Got 'mse' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'criterion' parameter of DecisionTreeRegressor must be a str among {'squared_error', 'friedman_mse', 'poisson', 'absolute_error'}. Got 'mse' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.5251667  0.51276527]\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 4 is smaller than n_iter=10. Running 4 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               model  Best Score       MAE       MSE      RMSE  R² Score\n",
      "0  linear_regression    0.373811  0.415479  0.279395  0.528578  0.672908\n",
      "1              lasso    0.387712  0.515180  0.416076  0.645039  0.512894\n",
      "2              ridge    0.374192  0.415659  0.279371  0.528555  0.672937\n",
      "3      decision_tree    0.525167  0.464950  0.549540  0.741310  0.356645\n",
      "4      random_forest    0.706689  0.317164  0.182046  0.426668  0.786876\n",
      "5                svr    0.708130  0.322946  0.193465  0.439846  0.773508\n",
      "6        k_neighbors    0.677622  0.350750  0.270193  0.519801  0.683681\n",
      "7                mlp    0.719916  0.309923  0.177139  0.420879  0.792621\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, ShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def find_best_model_using_randomizedsearchcv(X, y):\n",
    "    # Split the data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    \n",
    "    algos = {\n",
    "        'linear_regression': {\n",
    "            'model': LinearRegression(),\n",
    "            'params': {}\n",
    "        },\n",
    "        'lasso': {\n",
    "            'model': Lasso(),\n",
    "            'params': {\n",
    "                'alpha': [1, 2],\n",
    "                'selection': ['random', 'cyclic']\n",
    "            }\n",
    "        },\n",
    "        'ridge': {\n",
    "            'model': Ridge(),\n",
    "            'params': {\n",
    "                'alpha': [1, 2, 3]\n",
    "            }\n",
    "        },\n",
    "        'decision_tree': {\n",
    "            'model': DecisionTreeRegressor(),\n",
    "            'params': {\n",
    "                'criterion': ['mse', 'friedman_mse'],\n",
    "                'splitter': ['best', 'random']\n",
    "            }\n",
    "        },\n",
    "        'random_forest': {\n",
    "            'model': RandomForestRegressor(),\n",
    "            'params': {\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [None, 5],\n",
    "                'min_samples_split': [2, 5],\n",
    "                'min_samples_leaf': [1, 2]\n",
    "            }\n",
    "        },\n",
    "        'svr': {\n",
    "            'model': SVR(),\n",
    "            'params': {\n",
    "                'kernel': ['linear', 'rbf'],\n",
    "                'C': [0.1, 1],\n",
    "                'epsilon': [0.1, 0.2]\n",
    "            }\n",
    "        },\n",
    "        'k_neighbors': {\n",
    "            'model': KNeighborsRegressor(),\n",
    "            'params': {\n",
    "                'n_neighbors': [3, 5],\n",
    "                'weights': ['uniform', 'distance']\n",
    "            }\n",
    "        },\n",
    "        'mlp': {\n",
    "            'model': MLPRegressor(max_iter=1000),\n",
    "            'params': {\n",
    "                'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "                'activation': ['tanh', 'relu'],\n",
    "                'solver': ['adam', 'sgd']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    \n",
    "    for algo_name, config in algos.items():\n",
    "        # Perform randomized search to find the best parameters\n",
    "        rs = RandomizedSearchCV(\n",
    "            config['model'],\n",
    "            config['params'],\n",
    "            cv=cv,\n",
    "            n_iter=10,\n",
    "            n_jobs=-1,\n",
    "            return_train_score=False,\n",
    "            random_state=0\n",
    "        )\n",
    "        rs.fit(X_train, y_train)\n",
    "        \n",
    "        # Get the best model and make predictions on the test set\n",
    "        best_model = rs.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        # Calculate evaluation metrics\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        #  the best score from cross-validation\n",
    "        best_score = rs.best_score_\n",
    "        \n",
    "        # Store the results\n",
    "        results.append({\n",
    "            'model': algo_name,\n",
    "            'Best Score': best_score,\n",
    "            'MAE': mae,\n",
    "            'MSE': mse,\n",
    "            'RMSE': rmse,\n",
    "            'R² Score': r2,\n",
    "            'Best Parameters': rs.best_params_\n",
    "        })\n",
    "    \n",
    "    # Return the results as a DataFrame\n",
    "    return pd.DataFrame(results, columns=['model', 'Best Score', 'MAE', 'MSE', 'RMSE', 'R² Score'])\n",
    "\n",
    "# Example usage:\n",
    "df = find_best_model_using_randomizedsearchcv(X, y)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price: 2.3747830712125193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def predict_price(location, area, floors, road_width, road_type):\n",
    "    \"\"\"\n",
    "    Predict house price based on location, area, floors, road width, and road type\n",
    "    \n",
    "    Parameters:\n",
    "    location (str): One of 'City_Bhaktapur', 'City_Kathmandu', or 'City_Lalitpur'\n",
    "    area (float): Area of the property in square units\n",
    "    floors (float): Number of floors\n",
    "    road_width (float): Width of the road in front of the property\n",
    "    road_type (str): One of 'Road_Type_Blacktopped', 'Road_Type_Gravelled', or 'Road_Type_Soil Stabilized'\n",
    "    \n",
    "    Returns:\n",
    "    float: Predicted price\n",
    "    \"\"\"\n",
    "    # Initialize array with zeros for all features\n",
    "    x = np.zeros(len(X.columns))\n",
    "    \n",
    "    # Set the feature values\n",
    "    x[0] = floors  # Floors is the first column\n",
    "    x[1] = area    # Area is the second column\n",
    "    x[2] = road_width  # Road_Width is the third column\n",
    "    \n",
    "    # Set the location to 1 (one-hot encoding)\n",
    "    if location == 'City_Bhaktapur':\n",
    "        x[3] = 1\n",
    "    elif location == 'City_Kathmandu':\n",
    "        x[4] = 1\n",
    "    elif location == 'City_Lalitpur':\n",
    "        x[5] = 1\n",
    "    \n",
    "    # Set the road type to 1 (one-hot encoding)\n",
    "    if road_type == 'Road_Type_Blacktopped':\n",
    "        x[6] = 1\n",
    "    elif road_type == 'Road_Type_Gravelled':\n",
    "        x[7] = 1\n",
    "    elif road_type == 'Road_Type_Soil Stabilized':\n",
    "        x[8] = 1\n",
    "    \n",
    "    return lr_clf.predict([x])[0]\n",
    "\n",
    "# Test the model with sample data including road type\n",
    "predicted_price = predict_price('City_Kathmandu', 16.0, 2.0, 20.0, 'Road_Type_Blacktopped')\n",
    "print(f\"Predicted price: {predicted_price}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted price (MLP): 2.458860105703709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but MLPRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict_price_mlp(location, area, floors, road_width, road_type):\n",
    "    \"\"\"\n",
    "    Predict house price using the fitted MLPRegressor\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    location : str\n",
    "        One of 'City_Bhaktapur', 'City_Kathmandu', or 'City_Lalitpur'\n",
    "    area : float\n",
    "        Area of the property in square units\n",
    "    floors : float\n",
    "        Number of floors\n",
    "    road_width : float\n",
    "        Width of the road in front of the property\n",
    "    road_type : str\n",
    "        One of 'Road_Type_Blacktopped', 'Road_Type_Gravelled', or 'Road_Type_Soil Stabilized'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        The MLP‐predicted price\n",
    "    \"\"\"\n",
    "    # Create a zero‐vector as long as the number of features in X\n",
    "    x = np.zeros(len(X.columns))\n",
    "    \n",
    "    # Numeric features\n",
    "    x[ X.columns.get_loc('Floors')      ] = floors\n",
    "    x[ X.columns.get_loc('Area')        ] = area\n",
    "    x[ X.columns.get_loc('Road_Width')  ] = road_width\n",
    "    \n",
    "    # One‐hot encoding for location\n",
    "    loc_col = f\"City_{location.split('_')[1]}\"  # e.g. 'City_Kathmandu'\n",
    "    if loc_col in X.columns:\n",
    "        x[ X.columns.get_loc(loc_col) ] = 1\n",
    "    \n",
    "    # One‐hot encoding for road type\n",
    "    if road_type in X.columns:\n",
    "        x[ X.columns.get_loc(road_type) ] = 1\n",
    "    \n",
    "    # Predict with the MLP\n",
    "    return mlp_regressor.predict([x])[0]\n",
    "\n",
    "# ---- prediction ----\n",
    "predicted_price = predict_price_mlp(\n",
    "    location='City_Kathmandu', \n",
    "    area=16.0, \n",
    "    floors=2.0, \n",
    "    road_width=20.0, \n",
    "    road_type='Road_Type_Blacktopped'\n",
    ")\n",
    "print(f\"Predicted price (MLP): {predicted_price}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Actual_Price  Predicted_LR  Predicted_MLP\n",
      "343     -0.814354     -0.621697      -0.691087\n",
      "563     -0.480782     -0.544464      -0.652334\n",
      "285     -0.258401     -0.514646      -0.619863\n",
      "348     -0.869949     -0.715978      -0.883592\n",
      "228      3.688861      3.166022       2.243669\n",
      "134     -0.936663     -0.738177      -0.923778\n",
      "796     -1.203521     -0.883281      -0.912727\n",
      "84      -0.647568     -0.738565      -0.815093\n",
      "382      2.021003      1.042044       1.194719\n",
      "28      -0.619771     -0.389996      -0.546847\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Generate predictions on the test set\n",
    "y_pred_lr  = lr_clf.predict(X_test)\n",
    "y_pred_mlp = mlp_regressor.predict(X_test)\n",
    "\n",
    "# 2. Build a comparison DataFrame\n",
    "df_compare = pd.DataFrame({\n",
    "    'Actual_Price':       y_test,                        # true values\n",
    "    'Predicted_LR':       y_pred_lr,                     # linear model\n",
    "    'Predicted_MLP':      y_pred_mlp                     # neural net\n",
    "}, index=y_test.index)                                   # keep the same index as y_test\n",
    "\n",
    "# 3. Inspect the first few rows\n",
    "print(df_compare.head(10))\n",
    "\n",
    "# 4. (Optional) Save to CSV if you want to review externally\n",
    "df_compare.to_csv('price_comparison.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained MLP model\n",
    "with open('realstate_prices_mlp_model.pickle', 'wb') as f:\n",
    "    pickle.dump(mlp_regressor, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "columns = {\n",
    "    'data_columns' : [col.lower() for col in X.columns]\n",
    "}\n",
    "with open(\"columns.json\",\"w\") as f:\n",
    "    f.write(json.dumps(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPhj7X+c4ZB5Ed4TDt2uL56",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
